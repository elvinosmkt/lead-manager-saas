"""
VersÃ£o que salva TODAS as empresas, mostrando quais tÃªm/nÃ£o tÃªm site
"""
from scraper_selenium import GoogleMapsScraperSelenium
import pandas as pd
import os
from datetime import datetime
from config import CONFIG


class GoogleMapsScraperCompleto(GoogleMapsScraperSelenium):
    """VersÃ£o que coleta TODAS as empresas, independente de ter site ou WhatsApp"""
    
    def _collect_businesses(self):
        """Coleta informaÃ§Ãµes de TODAS as empresas"""
        from selenium.webdriver.common.by import By
        import time
        
        print("\nğŸ“Š Coletando informaÃ§Ãµes de TODAS as empresas...")
        
        try:
            # Scroll para carregar mais resultados
            self._scroll_results()
            
            # Pega todos os links de empresas
            print("ğŸ” Buscando links de empresas...")
            business_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/maps/place/"]')
            
            if not business_links:
                print("âš ï¸ Nenhuma empresa encontrada")
                return
            
            total = min(len(business_links), CONFIG["MAX_BUSINESSES"])
            print(f"ğŸ“ Encontradas {len(business_links)} empresas. Processando atÃ© {total}...\n")
            
            for idx in range(total):
                try:
                    # Re-busca os links a cada iteraÃ§Ã£o
                    business_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/maps/place/"]')
                    if idx >= len(business_links):
                        break
                    
                    print(f"[{idx+1}/{total}] Processando empresa...")
                    
                    # Clica no negÃ³cio
                    business_links[idx].click()
                    time.sleep(3)
                    
                    # Extrai as informaÃ§Ãµes
                    business_data = self._extract_business_info()
                    
                    if business_data:
                        # Adiciona TODAS as empresas
                        # Marca status
                        business_data['tem_site'] = 'Sim' if business_data.get('website') else 'NÃ£o'
                        business_data['tem_whatsapp'] = 'Sim' if business_data.get('whatsapp') else 'NÃ£o'
                        
                        self.businesses.append(business_data)
                        
                        status = []
                        if not business_data.get('website'):
                            status.append("SEM SITE")
                        if business_data.get('whatsapp'):
                            status.append("COM WHATSAPP")
                        
                        if status:
                            print(f"âœ… {business_data['nome']} [{', '.join(status)}]")
                        else:
                            print(f"ğŸ“‹ {business_data['nome']}")
                    
                    time.sleep(CONFIG["DELAY_BETWEEN_BUSINESSES"])
                    
                except Exception as e:
                    print(f"âš ï¸ Erro ao processar empresa {idx+1}: {str(e)}")
                    continue
                    
        except Exception as e:
            print(f"âŒ Erro ao coletar empresas: {str(e)}")
    
    def save_to_excel(self, filename: str = None):
        """Salva TODAS as empresas com indicador de site/whatsapp"""
        if not self.businesses:
            print("âš ï¸ Nenhuma empresa para salvar!")
            return
        
        os.makedirs(CONFIG["OUTPUT_DIR"], exist_ok=True)
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            cidade_limpa = self.cidade.replace(",", "").replace(" ", "_")
            filename = f"{CONFIG['OUTPUT_DIR']}/todas_empresas_{self.nicho}_{cidade_limpa}_{timestamp}.xlsx"
        
        df = pd.DataFrame(self.businesses)
        
        # Reordena as colunas
        columns = ['nome', 'tem_site', 'tem_whatsapp', 'telefone', 'whatsapp',  'endereco', 'avaliacao', 'num_avaliacoes', 'website']
        df = df[[col for col in columns if col in df.columns]]
        
        # Salva no Excel
        df.to_excel(filename, index=False, engine='openpyxl')
        
        # EstatÃ­sticas
        sem_site = len([b for b in self.businesses if not b.get('website')])
        com_whatsapp = len([b for b in self.businesses if b.get('whatsapp')])
        leads_qualificados = len([b for b in self.businesses if not b.get('website') and b.get('whatsapp')])
        
        print(f"\nğŸ“Š Arquivo salvo: {filename}")
        print(f"ğŸ“ˆ Total de empresas: {len(self.businesses)}")
        print(f"ğŸ” Sem website: {sem_site}")
        print(f"ğŸ’¬ Com WhatsApp: {com_whatsapp}")
        print(f"ğŸ¯ Leads qualificados (sem site + com WhatsApp): {leads_qualificados}")
        
        return filename


def main():
    print("=" * 60)
    print("ğŸ¯ GOOGLE MAPS - TODAS AS EMPRESAS")
    print("=" * 60)
    
    nicho = input("\nğŸ“Œ Digite o nicho (ex: estÃ©tica): ").strip()
    cidade = input("ğŸ“ Digite a cidade e estado (ex: Curitiba, PR): ").strip()
    
    if not nicho or not cidade:
        print("âŒ Nicho e cidade sÃ£o obrigatÃ³rios!")
        return
    
    print(f"\nğŸš€ Iniciando busca por '{nicho}' em '{cidade}'...")
    print("â³ Isso pode levar alguns minutos...\n")
    
    scraper = GoogleMapsScraperCompleto(nicho, cidade)
    
    try:
        scraper.scrape()
        
        if scraper.businesses:
            scraper.save_to_excel()
            print("\nâœ… Processo concluÃ­do com sucesso!")
        else:
            print("\nâš ï¸ Nenhuma empresa encontrada.")
    except Exception as e:
        print(f"\nâŒ Erro: {str(e)}")


if __name__ == "__main__":
    main()
